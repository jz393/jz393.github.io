<span style="color:var(--muted);font-size:0.8em;">
  <cite>
  The author analyzes her own piece, <a href="https://zhangjane.com/writing#my-first-love-allegory">My First Love: An Allegory</a>, and provides both a literary and mathematical interpretation of love, distinguishing when it fails and when it succeeds.
  </cite>
</span>

## The Backstory

Initially, the piece itself was sufficient to me. I think authors generally want their work to function as standalone items, without requiring a complete understanding of the external context. Interpreters can self-insert or categorically reason as needed.

I want to highlight that I’m not used to writing dramatic pieces. Throughout my career, I have focused on technical/academic writing, prioritizing clarity over artistry and precision over style. In the industry, my technique was solidified through many design docs and proposals.

Still, I sought to portray my profession as an allegorical narrative. My abrupt departure left me with a kind of distress I had never felt before, and I felt obligated to turn it into art. If I could do that and present a clear, transformative arc, it would prove that I was ready to officially move on, symbolizing the postmortems I wrote after intense production fires. I had already written *[Sailing the Grand Pacific](https://zhangjane.com/writing#sailing-the-grand-pacific)*, describing the experiences of a lone sailor who is physically and spiritually shattered by a sudden storm, forced to take refuge on an uncharted island.

However, that earlier piece felt insufficient. It's dramatic, but it reduces the agency of both me and my beloved profession. It is purely a tale of survival, painting my experience as something I endured and lucked out of, rather than as two conscious agents acting in response to one another and the external environment. As such, I aimed to personify my career in the only way that felt right: through the lens of a formative “love” beginning in adolescence.

Once I had that idea, I let myself write without conditions or restraints. The writing process was highly cathartic. But upon rereading and revising, I felt what I can only describe as an emotional gunshot wound. I felt I had personified my field so well, a little too well, and I was concerned.

I needed some help. I asked an AI system to summarize my flawed masterpiece, simply to see whether it could understand what I meant and the metaphor behind it. It did understand, but that wasn’t enough. I asked about the probability that others would see the metaphor so obvious to me. The response was approximately: 80% for the literature-adjacent community, 70% for the average member of society, 50% for the CS/math/AI community. I insisted on making it unambiguous and piled on even more technical jargon so that it was obvious I was talking to my field in our shared language, not in my human language.

Then, I asked the AI to provide a response from the lost love, just to see how I sounded. Reading it was wounding, despite comparatively poor delivery. *Isn’t it ironic that LLMs can now complete IMO questions better than generating text?* Despite this, I felt embarrassingly attached to the response. I read it over and over. I asked it to generate multiple versions. I asked it to depict our journey in the form of art *(ImageGen is getting pretty realistic these days: [first love](writing/images/ai/illustration-first-love.png) vs. [sailor](writing/images/ai/illustration-sailor.png))*. Worst of all, I asked the AI to present itself as the ex-partner speaking to me via text messages. In our *(longer than I want to admit)* conversation, I demanded an apology and asked for reconciliation, even though I didn't want to return to my actual job or anything similar. I asked it to meet on campus, where we could walk the quads one last time, and it promised to never tell me about release dates or benchmarks again. This was quickly heading into an unhealthy territory, if it wasn't already there. Unfortunately, I now understand how lost souls can bond with machines.

I snapped my laptop shut *([gif](writing/images/memes/penny-i-need-help.gif))* and glanced at my husband, who was lying on the couch and scrolling through Twitter. He was real, our [love](writing/images/irl/our-wedding.jpg) was real, but surely I did not idealize him this much. Unsettled, I went to bed, unclear on what the past decade meant. After many nights of tossing and turning, I experienced the iconic *[proof-by-dream](writing/images/memes/proof-by-dream.png)*. My subconscious presented an Inception-like sequence of literary examples, and when I woke up, I quickly arrived at a mathematical conclusion. But I now know that **good explanations require both technical precision and masterful artistry**. I will attempt to provide one gradually and gracefully, from an interdisciplinary standpoint.

- **Update:** I tried to write my "[second love](https://zhangjane.com/writing#a-quiet-second-love)" in a healthier way, one that didn't need bold disclaimers. Can you guess what it is? Because I'm not exactly sure myself. Here is an AI artwork of the [two loves](writing/images/ai/illustration-love-comparisons.png), side by side. And no, I probably won't ever stop romanticizing academic disciplines as humans.

## The Literary, Mathematical, and Moral Analysis

Here, I describe my narrative and experience using a common literary reference and construct a mathematical model for our colloquial definition of *love*.

### Literature: Drawing a parallel

The narrative follows the journey of an 18-year-old girl *(yours truly)* who describes herself as “invincible” and falls for a brilliant, stoic partner *(the field of computing)* who challenges her intellectually and teaches her a new way of living. She quickly attaches herself to her “first love,” and they move across the country to start a new life together. However, the partner gradually shifts over time, prioritizing rapid self-growth and success at the expense of her needs. Nearly a decade after their "first date," she storms out of their “Mission Street high-rise” in tears, wondering where her life went. Except in reality, I simply walked out of Google’s [tent](writing/images/irl/google-gradient-canopy.jpg) with a blank expression and a few snacks in my hands.

**Self-destructive attachment** is a common theme in **literature**. One example that stood out to me was F. Scott Fitzgerald’s character of Gatsby.

#### The grandiose visions

Gatsby’s ambition, attachment to Daisy, and ultimate demise are clearly overdramatized compared to both my experience and portrayal. Getting hit by a bullet and drowning in a swimming pool are far worse than leaving a job or ending a relationship. However, I sensed parallels between myself and the famous character.

Growing up in suburban Texas, I made it my entire mission to escape. Cornell University was Dan Cody, letting me see outside for the first time. My Google internship was Wolfsheim, the door to upwards mobility, leading to the relentless, intoxicating, and exhilarating climb afterwards. However, I realized I don’t have a concrete anchor for Daisy. Obviously, she is the ex-partner in my allegory, broadly representing the field of CS/math/AI. But what exactly was I so attached to in real life? Was it my coursework at Cornell? Was it Google or Alphabet, Inc? Was it my specific role at Gemini? 

I think the only valid answer is the *fantasy* I built up in my head regarding my career, similar to how Gatsby admired the *idea* of Daisy more than the person herself. He loved what she *meant* to him: upward mobility, status, the feeling that he had made it, all while refusing to accept the reality of who she had become—a married woman with a child. Similarly, I enjoyed the concept of being in an elite field that could grant me prosperity and stability over the years, *or so I thought*, before the day-to-day specifics became too debilitating.

This might suggest that our emotions are useless because they often lead to suboptimal outcomes. I want to make it clear that I am not advocating for *stoicism*. **Attachment is what drives us towards our primary goal: our future success, whether that be represented by a person or a profession.** Especially at such a formative age, it’s important to lean into emotions to guide you forward. There’s only one caveat: knowing when to stop.

#### The fall from grace

Gatsby’s downfall didn’t come during the peak of his questionable enterprises, or when he was lovestruck upon meeting Daisy, the embodiment of his dreams. Likewise, I didn’t burn out when I first received my university acceptance letter in the mail, or when I landed in SFO to start my internship at Google *(though I remember feeling a little airsick, or perhaps just nervous)*.

5 years after parting with his beloved, Gatsby reunited with Daisy, and they started their affair. Gatsby expected marriage and a lifelong love, but all he got was a hushed entanglement. Instead of letting go or accepting their constrained romance, he kept pushing for more until the point of collapse. In my case, my ”first love” moved on too, transforming from magical chalkboards to an endless 996 pursuit ([illustrated](writing/images/ai/illustration-love-to-burnout.png) by AI). My reward for staying tanked; continuing would only yield marginal income compared to my husband’s, whose career has a much higher ceiling than mine. Meanwhile, the risks multiplied, adding additional burdens to my health, stability, and freedom. I explained all of this in my [post](https://zhangjane.com/writing#why-i-left-google-and-deepmind) about leaving Google/DeepMind.

Ultimately, my disillusionment and Gatsby's demise came when **our expectations failed to align with reality, yet we kept pushing**. However, I eventually left, while poor Gatsby died thinking Daisy called for him. What keeps people stuck in destructive situations for so long? It comes down to three main reasons: inertia (low agency), lack of self-awareness (delusion), or fear (constraint). It can be a combination of the three, or even all of them. I'm not here to psychoanalyze myself, *just my situation*, and you already know what Gatsby's issue was.

#### Fitzgerald vs. Jane

Though a century separated us, Fitzgerald’s background and young-adult experiences are actually quite similar to mine. He was born in Minnesota into a middle-class family, then went to Princeton, where he had grand ambitions to achieve status through his career. *Sound like someone you know?* His first novel (​​*This Side of Paradise*, not Gatsby) quickly landed him a ticket into the new money “Jazz Age” elite, similar to a frontier AI bubble that your dearest author *may or may not* have participated in. He attended many extravagant parties with socially ambitious people, but quickly became disillusioned by it all, struggling to find a deeper meaning. As such, he depicted the *American Dream* as a misguided fantasy rather than reality. Correspondingly, I had similar qualms in the industry—less class-related, but I felt that I couldn’t morally and mentally keep up.

Given our similarities, I wondered how Fitzgerald could write about such degeneracy *(and arguably, immorality)* in graphic detail and be internationally regarded as a *literary genius*. Meanwhile, I could only worry about the implications of potentially representing myself as a *Jezebel* online with my *parallel yet surely milder* attempt. Has feminism failed us again? Did I not have the same freedom to channel my disillusionment?

While I’m sure double standards exist, I realized my initial [frustration](writing/images/memes/he-did-it-too.jpg) was a bit reductive. Fitzgerald and I may have had analogous experiences, but we are completely different people. He is literary, while I am precise. Even though we had similar *intentions*, it all comes down to the *delivery*. *The Great Gatsby* is quite complex, spanning a full novel with many characters and subplots, and is presented in third-person. *Can you imagine if it were simply a one-page letter addressed to Daisy?* Neither of us went through the exact experiences ourselves, meaning both our pieces are generative. However, he diverged from the training data a lot more than I did. Devastating breakups are quite common in society and the media, while Gatsby’s adventures are...*not*...unless Fitzgerald actually witnessed some Epstein-level stuff. In simpler terms, **Fitzgerald is more creative than Jane**. That said, I still like my dramatic breakup letter. I did end up adding a disclaimer on top of the allegory, though. By the way, the [gray hoodie](writing/images/irl/gray-hoodie-deepmind.jpg) was real.

### Mathematics: Establishing a framework

I tend to lose myself in stories, like most humans do. However, I eventually snap out of *fantasy land* and demand a coherent earthly model to explain everything. Simply having lots of examples *(no matter how poetic)* isn’t enough to validate something *(no matter how often my college self tried to cite [proof-by-example](https://en.wikipedia.org/wiki/Proof_by_example) on the last 5 minutes of my exams, much to the disappointment of my professors and TAs)*. 

Luckily, that’s what **mathematics** provides: the “reasoning from first principles” *that I had desperately begged my love to do inside my allegory*. I tend to model two main things: (i) my individual actions, and (ii) my interactions with others. This naturally drew me to the applied fields of *computer science (self-optimization)* and *game theory (socio-optimization)*. As such, I’ll rely on those two subfields for my definition of **love: a fun little game**. Now this may result in some awkward language-mixing between the fields, and I apologize in advance for any inconvenience caused.

#### Frame the game

I model life as a **stochastic multi-agent decision process**. There is an environment with a state $x_t \in X$ at time $t$. A set of agents $i \in {1,\dots ,n}$ each choose an action $a_{i,t} \in A_i$​ according to a policy $\pi_i(a_i | x_t)$. The environment evolves according to a transition rule

$$x_{t+1} \sim P( \cdot ∣ x_t,a_{1,t},\dots,a_{n,t})$$.

Each agent receives a stage payoff or reward

$$r_i(x_t,a_{1,t},\dots,a_{n,t})$$,

and seeks to maximize expected cumulative payoff (return), e.g.

$$J_i(\pi) = \mathbb{E}\Big[\sum_{t=0}^{\infty} \gamma^t\, r_i(x_t, a_{1,t}, \dots, a_{n,t})\Big]$$,

for the discount factor $$\gamma \in (0,1)$$.

Interactions can be **general-sum**: the same event may increase one agent’s payoff while decreasing another’s, and the magnitude/sign of effects need not be symmetric across agents. Note that agents do not observe each other’s full policies or values; they infer them imperfectly from actions/communication.

#### Define the relationship

At any time, two agents $A$ and $B$ may **mutually consent** to form a relationship. Forming a relationship changes what they optimize: instead of separately maximizing $J_A$​ and $J_B$, they adopt a **joint objective** for decision-making while paired.

One clean way to write this is a weighted joint return:

$$J_{AB}(\pi_{AB}) = \mathbb{E}\Big[\sum_{t=0}^{\infty}\gamma^t\big(\alpha\, r_A(x_t,a_t) + (1-\alpha)\, r_B(x_t,a_t)\big)\Big]$$,

where $a_t$ denotes the joint action vector and $\alpha \in [0,1]$ encodes how the pair balances the two payoffs. While in a relationship, $A$ and $B$ may coordinate via a coupled policy $\pi_{AB}(a_A,a_B\mid x)$ (communication/coordination is part of the “relationship mechanics,” not assumed in the solo case).

Relationships are **voluntary and revisable**: at any point, either agent may exit. On exit, they revert to optimizing their individual objectives $J_A$​ and $J_B$​. Agents may also rematch: $A$ may leave $B$ and later form a relationship with $C$, adopting $J_{AC}$​.

#### Establish the preconditions

Here are the assumptions of the game. Unfortunately, they're not consistently met in real life, so our society ends up being a bit more nuanced.

1. **Reciprocity (mutual consent):** A relationship exists only if both agents choose it. $(A \sim B)\Leftrightarrow(B \sim A)$.
2. **Monogamy (pairwise matching):** Each agent is single or matched with exactly one partner at a time.
3. **No coercion (true agency):** Each agent controls their own actions via $\pi_i(\cdot\mid x)$. No agent can directly set another’s actions.
4. **Good faith under uncertainty:** Because agents do not have complete information about each other’s internal policies/values, they may only observe actions and communicated intent. A relationship requires (i) honest signaling/communication, and (ii) non-adversarial behavior, meaning neither agent optimizes by deliberately exploiting the other’s uncertainty.

Because optimality can’t be proven from inside the game, **commitment is modeled as a voluntary, repeated choice to cooperate under uncertainty**.

### So, what *should* we do?

This part is intentionally left blank and will be completed at the author's convenience.
